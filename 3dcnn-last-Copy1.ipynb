{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "igpu = now.second%2; print(igpu)\n",
    "if igpu==0: \n",
    "     os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "else:\n",
    "     os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import random as rn\n",
    "#import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as keras\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv3D, MaxPooling3D, Activation, ZeroPadding3D\n",
    "from keras.layers import AveragePooling3D, BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adadelta, Adam, SGD\n",
    "from keras.utils import print_summary\n",
    "from keras.callbacks import ReduceLROnPlateau, TensorBoard, ModelCheckpoint, CSVLogger, LearningRateScheduler\n",
    "from keras.initializers import RandomNormal, glorot_normal, glorot_uniform, Constant\n",
    "from keras.regularizers import l2\n",
    "from keras.activations import relu, elu\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import load_model\n",
    "\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this should assure reproducibility\n",
    "np.random.seed(42)\n",
    "rn.seed(12345)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1,inter_op_parallelism_threads=1)\n",
    "tf.set_random_seed(1234)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_lambdas = ['1', '2', '3', '4', '5', '6', '8', '10', '12', '16', '20', '24', '28', '32', '36', '40']\n",
    "\n",
    "batch_size = 32\n",
    "test_split = 0.5\n",
    "period_checkpoint = 1\n",
    "epochs = 100\n",
    "\n",
    "model_select = 30\n",
    "\n",
    "data_augment = 'False'\n",
    "predict_control = 'False'\n",
    "showconfs = 'True'\n",
    "statconfs = 'False'\n",
    "cvs_logger_control = 'True'\n",
    "lr_scheduler_control = 'False'\n",
    "\n",
    "hdf5_path = 'data/dataset.hdf5'\n",
    "TB_dir = './TB'\n",
    "checkpoint_path = './checkpoints/best.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = ModelCheckpoint(checkpoint_path, \n",
    "                              monitor='val_loss', \n",
    "                              verbose=1,\n",
    "                              save_best_only=True, \n",
    "                              save_weights_only=False, \n",
    "                              mode='auto', \n",
    "                              period=period_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs_logger = CSVLogger('log.keras', separator=' ', append=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', \n",
    "                              factor=0.5, \n",
    "                              patience=2, \n",
    "                              verbose=1,\n",
    "                              mode='auto', \n",
    "                              min_delta=0.0001, \n",
    "                              cooldown=0, \n",
    "                              min_lr=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(hdf5_path, 'r') as h5:\n",
    "    print(\"Keys in hdf5: %s\" % list(h5.keys()))\n",
    "    x_train, y_train = h5[\"train_data\"][:], h5[\"train_labels\"][:]\n",
    "    x_test, y_test = h5[\"test_data\"][:], h5[\"test_labels\"][:]\n",
    "nx = x_train.shape[1]\n",
    "ny = x_train.shape[2]\n",
    "nz = x_train.shape[3]\n",
    "nch = x_train.shape[4]\n",
    "nsmpl = x_train.shape[0]\n",
    "n_classes = len(class_lambdas)\n",
    "print (nx, ny, nz, nch, nsmpl, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_augment == 'True':\n",
    "    noise_factor=0.25\n",
    "    train_average=np.mean(x_train, axis=(0, 1, 2, 3))\n",
    "    train_std_dev=np.std(x_train, axis=(0, 1, 2, 3))\n",
    "    x_augm=np.copy(x_train)\n",
    "    y_augm=np.copy(y_train)\n",
    "    for ic in range(nch):\n",
    "        x_augm[:, :, :, :, ic]+=noise_factor*np.random.normal(loc=train_average[ic], scale=train_std_dev[ic], size=x_augm[:, :, :, :, ic].shape) \n",
    "    x_new=np.concatenate((x_train, x_augm), axis=0)\n",
    "    y_new=np.concatenate((y_train, y_augm), axis=0)\n",
    "    x_train=x_new\n",
    "    y_train=y_new\n",
    "    del(x_augm)\n",
    "    del(y_augm)\n",
    "    del(x_new)\n",
    "    del(y_new)\n",
    "    print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, train_size=test_split, random_state=0)\n",
    "print(x_val.shape, y_val.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_average=np.mean(x_train, axis=(0, 1, 2, 3))\n",
    "train_std_dev=np.std(x_train, axis=(0, 1, 2, 3))\n",
    "x_train-=train_average\n",
    "x_train/=train_std_dev\n",
    "x_val-=train_average\n",
    "x_val/=train_std_dev\n",
    "x_test-=train_average\n",
    "x_test/=train_std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_augment == 'True':\n",
    "    n_sample = np.rint(np.random.rand()*x_train.shape[0]/2-1).astype(int)\n",
    "    nsmpl2 = n_sample+int(x_train.shape[0]/2)\n",
    "    n_slice = np.rint(np.random.rand()*nx-1).astype(int)\n",
    "    print(n_sample, y_train[n_sample], n_slice)\n",
    "    print(nsmpl2)\n",
    "\n",
    "    fwidth = 20\n",
    "    flength = fwidth/3.3\n",
    "\n",
    "    for ic in range(nch):\n",
    "\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(fwidth, flength))\n",
    "        fig.subplots_adjust(hspace =.0, wspace=.0)\n",
    "        axs = axs.ravel()\n",
    "\n",
    "        c0=axs[0].contourf(x_train[n_sample, :, :, n_slice, ic]) \n",
    "        axs[0].axis('off')\n",
    "        axs[0].legend([\"orig\", ic]) \n",
    "        fig.colorbar(c0, ax=axs[0], shrink=0.5)\n",
    "\n",
    "        c1=axs[1].contourf(x_train[nsmpl2, :, :, n_slice, ic]) \n",
    "        axs[1].axis('off')\n",
    "        axs[1].legend([\"augm\", ic]) \n",
    "        fig.colorbar(c1, ax=axs[1], shrink=0.5)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = x_train.shape[0]\n",
    "nx = x_train.shape[1]\n",
    "ny = x_train.shape[2]\n",
    "nz = x_train.shape[3]\n",
    "nch = x_train.shape[4]\n",
    "n_classes = len(class_lambdas)\n",
    "ntest = x_test.shape[0]\n",
    "nval = x_val.shape[0]\n",
    "\n",
    "#if you want to restrict to 1 channel only\n",
    "#\n",
    "#dum_train = x_train; dum_test = x_test; del x_train; del x_test\n",
    "#x_train = dum_train [:, :, :, :, 0]; x_test = dum_test [:, :, :, :, 0]\n",
    "#del dum_train; del dum_test\n",
    "#nch = 1\n",
    "#x_train = x_train.reshape(ntrain, nx, ny, nz, nch)\n",
    "#x_test = x_test.reshape(ntest, nx, ny, nz, nch)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "\n",
    "input_shape = (nx, ny, nz, nch)\n",
    "\n",
    "print ('train data shape is', x_train.shape)\n",
    "print ('train labels shape is', y_train.shape)\n",
    "print ('valid data shape is', x_val.shape)\n",
    "print ('valid labels shape is', y_val.shape)\n",
    "print ('test data shape is', x_test.shape)\n",
    "print ('test labels shape is', y_test.shape)\n",
    "print ('ntrain nx ny nz nch ', ntrain, nx, ny, nz, nch)\n",
    "print ('input shape is ', input_shape)\n",
    "print ('number of classes ',n_classes)\n",
    "\n",
    "print(\"class lambda sanity check\")\n",
    "for ic in range(n_classes):\n",
    "    print(ic, class_lambdas[ic],(y_train==ic).sum(), int(len(x_train[y_train==ic, :, :, :, 0].flatten())/nx/ny/nz))\n",
    "for ic in range(n_classes):\n",
    "    print(ic, class_lambdas[ic],(y_val==ic).sum(), int(len(x_val[y_val==ic, :, :, :, 0].flatten())/nx/ny/nz))\n",
    "for ic in range(n_classes):\n",
    "    print(ic, class_lambdas[ic],(y_test==ic).sum(), int(len(x_test[y_test==ic, :, :, :, 0].flatten())/nx/ny/nz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 30 this is the best so far\n",
    "# from https://gist.github.com/albertomontesg/d8b21a179c1e6cca0480ebdf292c34d2\n",
    "#\n",
    "if model_select == 30:\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(16, (3, 3, 3), activation='relu', \n",
    "                            padding='same', name='conv1',\n",
    "                            strides=(1, 1, 1), \n",
    "                            input_shape=input_shape))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='same', name='pool1'))\n",
    "    model.add(Conv3D(32, (3, 3, 3), activation='relu', \n",
    "                            padding='same', name='conv2',\n",
    "                            strides=(1, 1, 1)))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='same', name='pool2'))\n",
    "    model.add(Conv3D(64, (3, 3, 3), activation='relu', \n",
    "                            padding='same', name='conv3a',\n",
    "                            strides=(1, 1, 1)))\n",
    "    model.add(Conv3D(64, (3, 3, 3), activation='relu', \n",
    "                            padding='same', name='conv3b',\n",
    "                            strides=(1, 1, 1)))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='same', name='pool3'))\n",
    "    model.add(Conv3D(128, (3, 3, 3), activation='relu', \n",
    "                            padding='same', name='conv4a',\n",
    "                            strides=(1, 1, 1)))\n",
    "    model.add(Conv3D(128, (3, 3, 3), activation='relu', \n",
    "                            padding='same', name='conv4b',\n",
    "                            strides=(1, 1, 1)))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='same', name='pool4'))\n",
    "    model.add(Conv3D(128, (3, 3, 3), activation='relu', \n",
    "                            padding='same', name='conv5a',\n",
    "                            strides=(1, 1, 1)))\n",
    "    model.add(Conv3D(128, (3, 3, 3), activation='relu', \n",
    "                            padding='same', name='conv5b',\n",
    "                            strides=(1, 1, 1)))\n",
    "    model.add(ZeroPadding3D(padding=(1, 1, 1)))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), \n",
    "                           padding='same', name='pool5'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1028, activation='relu', name='fc6'))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Dense(1028, activation='relu', name='fc7'))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Dense(n_classes, activation='softmax', name='fc8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_select == 1:\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(32, kernel_size=(3, 3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv3D(64, (3, 3, 3), activation='relu'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [checkpoints, ]\n",
    "\n",
    "if cvs_logger_control == 'True':\n",
    "    callbacks.append(cvs_logger)\n",
    "\n",
    "if lr_scheduler_control == 'True':\n",
    "    callbacks.append(lr_scheduler) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, \n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "print_summary(model, line_length=None, positions=None, print_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, \n",
    "          y_train, \n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=(x_val, y_val),\n",
    "          shuffle='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = model.predict(x_test)\n",
    "n_samples = x_test.shape[0]\n",
    "pred = np.argmax(predicts, axis=1)\n",
    "print(accuracy_score(pred,y_test))\n",
    "array = confusion_matrix(y_test, pred)\n",
    "cm = pd.DataFrame(array, index = range(n_classes), columns = range(n_classes))\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
