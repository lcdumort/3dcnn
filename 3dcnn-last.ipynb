{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "igpu = now.second%2; print(igpu)\n",
    "if igpu==0: \n",
    "     os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "else:\n",
    "     os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n",
      "2.2.4-tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import random as rn\n",
    "#import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as keras\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv3D, MaxPooling3D, Activation, ZeroPadding3D\n",
    "from keras.layers import AveragePooling3D, BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adadelta, Adam, SGD\n",
    "from keras.utils import print_summary\n",
    "from keras.callbacks import ReduceLROnPlateau, TensorBoard, ModelCheckpoint, CSVLogger, LearningRateScheduler\n",
    "from keras.initializers import RandomNormal, glorot_normal, glorot_uniform, Constant\n",
    "from keras.regularizers import l2\n",
    "from keras.activations import relu, elu\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import load_model\n",
    "\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this should assure reproducibility\n",
    "np.random.seed(42)\n",
    "rn.seed(12345)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1,inter_op_parallelism_threads=1)\n",
    "tf.set_random_seed(1234)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_lambdas = ['1', '2', '3', '4', '5', '6', '8', '10', '12', '16', '20', '24', '28', '32', '36', '40']\n",
    "\n",
    "batch_size = 32\n",
    "test_split = 0.5\n",
    "period_checkpoint = 1\n",
    "epochs = 100\n",
    "\n",
    "model_select = 30\n",
    "\n",
    "data_augment = 'False'\n",
    "predict_control = 'False'\n",
    "showconfs = 'True'\n",
    "statconfs = 'False'\n",
    "cvs_logger_control = 'True'\n",
    "lr_scheduler_control = 'False'\n",
    "\n",
    "hdf5_path = 'data/dataset.hdf5'\n",
    "TB_dir = './TB'\n",
    "checkpoint_path = './checkpoints/best.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = ModelCheckpoint(checkpoint_path, \n",
    "                              monitor='val_loss', \n",
    "                              verbose=1,\n",
    "                              save_best_only=True, \n",
    "                              save_weights_only=False, \n",
    "                              mode='auto', \n",
    "                              period=period_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs_logger = CSVLogger('log.keras', separator=' ', append=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', \n",
    "                              factor=0.5, \n",
    "                              patience=2, \n",
    "                              verbose=1,\n",
    "                              mode='auto', \n",
    "                              min_delta=0.0001, \n",
    "                              cooldown=0, \n",
    "                              min_lr=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(hdf5_path, 'r') as h5:\n",
    "    print(\"Keys in hdf5: %s\" % list(h5.keys()))\n",
    "    x_train, y_train = h5[\"train_data\"][:], h5[\"train_labels\"][:]\n",
    "    x_test, y_test = h5[\"test_data\"][:], h5[\"test_labels\"][:]\n",
    "nx = x_train.shape[1]\n",
    "ny = x_train.shape[2]\n",
    "nz = x_train.shape[3]\n",
    "nch = x_train.shape[4]\n",
    "nsmpl = x_train.shape[0]\n",
    "n_classes = len(class_lambdas)\n",
    "print (nx, ny, nz, nch, nsmpl, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_augment == 'True':\n",
    "    noise_factor=0.25\n",
    "    train_average=np.mean(x_train, axis=(0, 1, 2, 3))\n",
    "    train_std_dev=np.std(x_train, axis=(0, 1, 2, 3))\n",
    "    x_augm=np.copy(x_train)\n",
    "    y_augm=np.copy(y_train)\n",
    "    for ic in range(nch):\n",
    "        x_augm[:, :, :, :, ic]+=noise_factor*np.random.normal(loc=train_average[ic], scale=train_std_dev[ic], size=x_augm[:, :, :, :, ic].shape) \n",
    "    x_new=np.concatenate((x_train, x_augm), axis=0)\n",
    "    y_new=np.concatenate((y_train, y_augm), axis=0)\n",
    "    x_train=x_new\n",
    "    y_train=y_new\n",
    "    del(x_augm)\n",
    "    del(y_augm)\n",
    "    del(x_new)\n",
    "    del(y_new)\n",
    "    print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, train_size=test_split, random_state=0)\n",
    "print(x_val.shape, y_val.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_average=np.mean(x_train, axis=(0, 1, 2, 3))\n",
    "train_std_dev=np.std(x_train, axis=(0, 1, 2, 3))\n",
    "x_train-=train_average\n",
    "x_train/=train_std_dev\n",
    "x_val-=train_average\n",
    "x_val/=train_std_dev\n",
    "x_test-=train_average\n",
    "x_test/=train_std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADDED BY LOICtrain_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_augment == 'True':\n",
    "    n_sample = np.rint(np.random.rand()*x_train.shape[0]/2-1).astype(int)\n",
    "    nsmpl2 = n_sample+int(x_train.shape[0]/2)\n",
    "    n_slice = np.rint(np.random.rand()*nx-1).astype(int)\n",
    "    print(n_sample, y_train[n_sample], n_slice)\n",
    "    print(nsmpl2)\n",
    "\n",
    "    fwidth = 20\n",
    "    flength = fwidth/3.3\n",
    "\n",
    "    for ic in range(nch):\n",
    "\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(fwidth, flength))\n",
    "        fig.subplots_adjust(hspace =.0, wspace=.0)\n",
    "        axs = axs.ravel()\n",
    "\n",
    "        c0=axs[0].contourf(x_train[n_sample, :, :, n_slice, ic]) \n",
    "        axs[0].axis('off')\n",
    "        axs[0].legend([\"orig\", ic]) \n",
    "        fig.colorbar(c0, ax=axs[0], shrink=0.5)\n",
    "\n",
    "        c1=axs[1].contourf(x_train[nsmpl2, :, :, n_slice, ic]) \n",
    "        axs[1].axis('off')\n",
    "        axs[1].legend([\"augm\", ic]) \n",
    "        fig.colorbar(c1, ax=axs[1], shrink=0.5)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape is (25600, 32, 32, 32, 3)\n",
      "train labels shape is (25600,)\n",
      "valid data shape is (3200, 32, 32, 32, 3)\n",
      "valid labels shape is (3200,)\n",
      "test data shape is (3200, 32, 32, 32, 3)\n",
      "test labels shape is (3200,)\n",
      "ntrain nx ny nz nch  25600 32 32 32 3\n",
      "input shape is  (32, 32, 32, 3)\n",
      "number of classes  16\n",
      "class lambda sanity check\n",
      "0 1 1612 1612\n",
      "1 2 1592 1592\n",
      "2 3 1581 1581\n",
      "3 4 1635 1635\n",
      "4 5 1588 1588\n",
      "5 6 1621 1621\n",
      "6 8 1573 1573\n",
      "7 10 1593 1593\n",
      "8 12 1604 1604\n",
      "9 16 1613 1613\n",
      "10 20 1630 1630\n",
      "11 24 1574 1574\n",
      "12 28 1612 1612\n",
      "13 32 1585 1585\n",
      "14 36 1596 1596\n",
      "15 40 1591 1591\n",
      "0 1 199 199\n",
      "1 2 196 196\n",
      "2 3 212 212\n",
      "3 4 178 178\n",
      "4 5 203 203\n",
      "5 6 185 185\n",
      "6 8 206 206\n",
      "7 10 202 202\n",
      "8 12 196 196\n",
      "9 16 191 191\n",
      "10 20 193 193\n",
      "11 24 209 209\n",
      "12 28 190 190\n",
      "13 32 210 210\n",
      "14 36 206 206\n",
      "15 40 224 224\n",
      "0 1 189 189\n",
      "1 2 212 212\n",
      "2 3 207 207\n",
      "3 4 187 187\n",
      "4 5 209 209\n",
      "5 6 194 194\n",
      "6 8 221 221\n",
      "7 10 205 205\n",
      "8 12 200 200\n",
      "9 16 196 196\n",
      "10 20 177 177\n",
      "11 24 217 217\n",
      "12 28 198 198\n",
      "13 32 205 205\n",
      "14 36 198 198\n",
      "15 40 185 185\n"
     ]
    }
   ],
   "source": [
    "ntrain = x_train.shape[0]\n",
    "nx = x_train.shape[1]\n",
    "ny = x_train.shape[2]\n",
    "nz = x_train.shape[3]\n",
    "nch = x_train.shape[4]\n",
    "n_classes = len(class_lambdas)\n",
    "ntest = x_test.shape[0]\n",
    "nval = x_val.shape[0]\n",
    "\n",
    "#if you want to restrict to 1 channel only\n",
    "#\n",
    "#dum_train = x_train; dum_test = x_test; del x_train; del x_test\n",
    "#x_train = dum_train [:, :, :, :, 0]; x_test = dum_test [:, :, :, :, 0]\n",
    "#del dum_train; del dum_test\n",
    "#nch = 1\n",
    "#x_train = x_train.reshape(ntrain, nx, ny, nz, nch)\n",
    "#x_test = x_test.reshape(ntest, nx, ny, nz, nch)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "\n",
    "input_shape = (nx, ny, nz, nch)\n",
    "\n",
    "print ('train data shape is', x_train.shape)\n",
    "print ('train labels shape is', y_train.shape)\n",
    "print ('valid data shape is', x_val.shape)\n",
    "print ('valid labels shape is', y_val.shape)\n",
    "print ('test data shape is', x_test.shape)\n",
    "print ('test labels shape is', y_test.shape)\n",
    "print ('ntrain nx ny nz nch ', ntrain, nx, ny, nz, nch)\n",
    "print ('input shape is ', input_shape)\n",
    "print ('number of classes ',n_classes)\n",
    "\n",
    "print(\"class lambda sanity check\")\n",
    "for ic in range(n_classes):\n",
    "    print(ic, class_lambdas[ic],(y_train==ic).sum(), int(len(x_train[y_train==ic, :, :, :, 0].flatten())/nx/ny/nz))\n",
    "for ic in range(n_classes):\n",
    "    print(ic, class_lambdas[ic],(y_val==ic).sum(), int(len(x_val[y_val==ic, :, :, :, 0].flatten())/nx/ny/nz))\n",
    "for ic in range(n_classes):\n",
    "    print(ic, class_lambdas[ic],(y_test==ic).sum(), int(len(x_test[y_test==ic, :, :, :, 0].flatten())/nx/ny/nz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 30 this is the best so far\n",
    "# from https://gist.github.com/albertomontesg/d8b21a179c1e6cca0480ebdf292c34d2\n",
    "#\n",
    "if model_select == 30:\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(16, (3, 3, 3), activation='relu', \n",
    "                            padding='same', name='conv1',\n",
    "                            strides=(1, 1, 1), \n",
    "                            input_shape=input_shape))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='same', name='pool1'))\n",
    "    model.add(Conv3D(32, (3, 3, 3), activation='relu', \n",
    "                            padding='same', name='conv2',\n",
    "                            strides=(1, 1, 1)))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='same', name='pool2'))\n",
    "    model.add(Conv3D(64, (3, 3, 3), activation='relu', \n",
    "                            padding='same', name='conv3a',\n",
    "                            strides=(1, 1, 1)))\n",
    "    model.add(Conv3D(64, (3, 3, 3), activation='relu', \n",
    "                            padding='same', name='conv3b',\n",
    "                            strides=(1, 1, 1)))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='same', name='pool3'))\n",
    "    model.add(Conv3D(128, (3, 3, 3), activation='relu', \n",
    "                            padding='same', name='conv4a',\n",
    "                            strides=(1, 1, 1)))\n",
    "    model.add(Conv3D(128, (3, 3, 3), activation='relu', \n",
    "                            padding='same', name='conv4b',\n",
    "                            strides=(1, 1, 1)))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='same', name='pool4'))\n",
    "    model.add(Conv3D(128, (3, 3, 3), activation='relu', \n",
    "                            padding='same', name='conv5a',\n",
    "                            strides=(1, 1, 1)))\n",
    "    model.add(Conv3D(128, (3, 3, 3), activation='relu', \n",
    "                            padding='same', name='conv5b',\n",
    "                            strides=(1, 1, 1)))\n",
    "    model.add(ZeroPadding3D(padding=(1, 1, 1)))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), \n",
    "                           padding='same', name='pool5'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1028, activation='relu', name='fc6'))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Dense(1028, activation='relu', name='fc7'))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Dense(n_classes, activation='softmax', name='fc8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_select == 1:\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(32, kernel_size=(3, 3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv3D(64, (3, 3, 3), activation='relu'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [checkpoints, ]\n",
    "\n",
    "if cvs_logger_control == 'True':\n",
    "    callbacks.append(cvs_logger)\n",
    "\n",
    "if lr_scheduler_control == 'True':\n",
    "    callbacks.append(lr_scheduler) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv3D)               (None, 32, 32, 32, 16)    1312      \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling3D)         (None, 16, 16, 16, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv3D)               (None, 16, 16, 16, 32)    13856     \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling3D)         (None, 8, 8, 8, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv3a (Conv3D)              (None, 8, 8, 8, 64)       55360     \n",
      "_________________________________________________________________\n",
      "conv3b (Conv3D)              (None, 8, 8, 8, 64)       110656    \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling3D)         (None, 4, 4, 4, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv4a (Conv3D)              (None, 4, 4, 4, 128)      221312    \n",
      "_________________________________________________________________\n",
      "conv4b (Conv3D)              (None, 4, 4, 4, 128)      442496    \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling3D)         (None, 2, 2, 2, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv5a (Conv3D)              (None, 2, 2, 2, 128)      442496    \n",
      "_________________________________________________________________\n",
      "conv5b (Conv3D)              (None, 2, 2, 2, 128)      442496    \n",
      "_________________________________________________________________\n",
      "zero_padding3d_1 (ZeroPaddin (None, 4, 4, 4, 128)      0         \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling3D)         (None, 2, 2, 2, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 1028)              1053700   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1028)              0         \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 1028)              1057812   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1028)              0         \n",
      "_________________________________________________________________\n",
      "fc8 (Dense)                  (None, 16)                16464     \n",
      "=================================================================\n",
      "Total params: 3,857,960\n",
      "Trainable params: 3,857,960\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer, \n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "print_summary(model, line_length=None, positions=None, print_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25600 samples, validate on 3200 samples\n",
      "Epoch 1/100\n",
      "25600/25600 [==============================] - 27s 1ms/step - loss: 2.7637 - acc: 0.0818 - val_loss: 2.7424 - val_acc: 0.1775\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.74237, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 2/100\n",
      "25600/25600 [==============================] - 25s 968us/step - loss: 2.7210 - acc: 0.1411 - val_loss: 2.6586 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.74237 to 2.65864, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 3/100\n",
      "25600/25600 [==============================] - 25s 972us/step - loss: 2.5672 - acc: 0.2701 - val_loss: 2.2880 - val_acc: 0.7441\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.65864 to 2.28795, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 4/100\n",
      "25600/25600 [==============================] - 25s 972us/step - loss: 2.0400 - acc: 0.4601 - val_loss: 1.3837 - val_acc: 0.8291\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.28795 to 1.38367, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 5/100\n",
      "25600/25600 [==============================] - 25s 974us/step - loss: 1.4034 - acc: 0.5936 - val_loss: 0.8692 - val_acc: 0.8206\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.38367 to 0.86917, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 6/100\n",
      "25600/25600 [==============================] - 25s 970us/step - loss: 1.0471 - acc: 0.6739 - val_loss: 0.6626 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.86917 to 0.66255, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 7/100\n",
      "25600/25600 [==============================] - 25s 976us/step - loss: 0.8559 - acc: 0.7211 - val_loss: 0.5546 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.66255 to 0.55456, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 8/100\n",
      "25600/25600 [==============================] - 25s 980us/step - loss: 0.7153 - acc: 0.7567 - val_loss: 0.4796 - val_acc: 0.9197\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.55456 to 0.47964, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 9/100\n",
      "25600/25600 [==============================] - 25s 978us/step - loss: 0.6233 - acc: 0.7793 - val_loss: 0.4247 - val_acc: 0.9622\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.47964 to 0.42472, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 10/100\n",
      "25600/25600 [==============================] - 25s 967us/step - loss: 0.5552 - acc: 0.7967 - val_loss: 0.3784 - val_acc: 0.9678\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.42472 to 0.37841, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 11/100\n",
      "25600/25600 [==============================] - 25s 977us/step - loss: 0.4948 - acc: 0.8189 - val_loss: 0.3362 - val_acc: 0.9531\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.37841 to 0.33616, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 12/100\n",
      "25600/25600 [==============================] - 25s 976us/step - loss: 0.4404 - acc: 0.8400 - val_loss: 0.2888 - val_acc: 0.9544\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.33616 to 0.28881, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 13/100\n",
      "25600/25600 [==============================] - 25s 973us/step - loss: 0.3822 - acc: 0.8675 - val_loss: 0.2405 - val_acc: 0.9875\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.28881 to 0.24047, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 14/100\n",
      "25600/25600 [==============================] - 25s 973us/step - loss: 0.3262 - acc: 0.8887 - val_loss: 0.2017 - val_acc: 0.9916\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.24047 to 0.20174, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 15/100\n",
      "25600/25600 [==============================] - 25s 971us/step - loss: 0.2796 - acc: 0.9066 - val_loss: 0.1634 - val_acc: 0.9900\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.20174 to 0.16343, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 16/100\n",
      "25600/25600 [==============================] - 25s 973us/step - loss: 0.2372 - acc: 0.9201 - val_loss: 0.1339 - val_acc: 0.9859\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.16343 to 0.13395, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 17/100\n",
      "25600/25600 [==============================] - 25s 973us/step - loss: 0.2001 - acc: 0.9314 - val_loss: 0.1085 - val_acc: 0.9938\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.13395 to 0.10846, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 18/100\n",
      "25600/25600 [==============================] - 25s 972us/step - loss: 0.1680 - acc: 0.9450 - val_loss: 0.0887 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.10846 to 0.08869, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 19/100\n",
      "25600/25600 [==============================] - 25s 967us/step - loss: 0.1409 - acc: 0.9559 - val_loss: 0.0683 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.08869 to 0.06834, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 20/100\n",
      "25600/25600 [==============================] - 25s 969us/step - loss: 0.1182 - acc: 0.9634 - val_loss: 0.0544 - val_acc: 0.9972\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.06834 to 0.05444, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 21/100\n",
      "25600/25600 [==============================] - 25s 972us/step - loss: 0.0984 - acc: 0.9709 - val_loss: 0.0461 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.05444 to 0.04607, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 22/100\n",
      "25600/25600 [==============================] - 25s 970us/step - loss: 0.0823 - acc: 0.9756 - val_loss: 0.0386 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.04607 to 0.03863, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 23/100\n",
      "25600/25600 [==============================] - 25s 976us/step - loss: 0.0690 - acc: 0.9804 - val_loss: 0.0288 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.03863 to 0.02879, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 24/100\n",
      "25600/25600 [==============================] - 25s 974us/step - loss: 0.0564 - acc: 0.9854 - val_loss: 0.0222 - val_acc: 0.9978\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.02879 to 0.02222, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 25/100\n",
      "25600/25600 [==============================] - 25s 962us/step - loss: 0.0458 - acc: 0.9880 - val_loss: 0.0153 - val_acc: 0.9994\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.02222 to 0.01535, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 26/100\n",
      "25600/25600 [==============================] - 25s 971us/step - loss: 0.0387 - acc: 0.9903 - val_loss: 0.0118 - val_acc: 0.9997\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.01535 to 0.01180, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 27/100\n",
      "25600/25600 [==============================] - 25s 966us/step - loss: 0.0321 - acc: 0.9929 - val_loss: 0.0098 - val_acc: 0.9997\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.01180 to 0.00975, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 28/100\n",
      "25600/25600 [==============================] - 25s 972us/step - loss: 0.0256 - acc: 0.9950 - val_loss: 0.0086 - val_acc: 0.9997\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00975 to 0.00865, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 29/100\n",
      "25600/25600 [==============================] - 25s 975us/step - loss: 0.0215 - acc: 0.9958 - val_loss: 0.0055 - val_acc: 0.9997\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00865 to 0.00549, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 30/100\n",
      "25600/25600 [==============================] - 25s 968us/step - loss: 0.0185 - acc: 0.9961 - val_loss: 0.0051 - val_acc: 0.9997\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00549 to 0.00505, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 31/100\n",
      "25600/25600 [==============================] - 25s 977us/step - loss: 0.0145 - acc: 0.9969 - val_loss: 0.0038 - val_acc: 0.9997\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00505 to 0.00383, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 32/100\n",
      "25600/25600 [==============================] - 25s 979us/step - loss: 0.0128 - acc: 0.9975 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00383 to 0.00215, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 33/100\n",
      "25600/25600 [==============================] - 25s 971us/step - loss: 0.0098 - acc: 0.9984 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00215 to 0.00189, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 34/100\n",
      "25600/25600 [==============================] - 25s 970us/step - loss: 0.0092 - acc: 0.9984 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00189 to 0.00149, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 35/100\n",
      "25600/25600 [==============================] - 25s 961us/step - loss: 0.0079 - acc: 0.9985 - val_loss: 9.1416e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00149 to 0.00091, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 36/100\n",
      "25600/25600 [==============================] - 25s 965us/step - loss: 0.0060 - acc: 0.9989 - val_loss: 7.2727e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00091 to 0.00073, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 37/100\n",
      "25600/25600 [==============================] - 25s 967us/step - loss: 0.0054 - acc: 0.9992 - val_loss: 8.4838e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00073\n",
      "Epoch 38/100\n",
      "25600/25600 [==============================] - 25s 965us/step - loss: 0.0049 - acc: 0.9990 - val_loss: 4.9158e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00073 to 0.00049, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 39/100\n",
      "25600/25600 [==============================] - 25s 966us/step - loss: 0.0042 - acc: 0.9994 - val_loss: 6.6455e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00049\n",
      "Epoch 40/100\n",
      "25600/25600 [==============================] - 25s 967us/step - loss: 0.0036 - acc: 0.9994 - val_loss: 3.4351e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00049 to 0.00034, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 41/100\n",
      "25600/25600 [==============================] - 25s 968us/step - loss: 0.0033 - acc: 0.9994 - val_loss: 3.8812e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00034\n",
      "Epoch 42/100\n",
      "25600/25600 [==============================] - 25s 969us/step - loss: 0.0029 - acc: 0.9995 - val_loss: 2.3641e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00034 to 0.00024, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 43/100\n",
      "25600/25600 [==============================] - 25s 969us/step - loss: 0.0027 - acc: 0.9995 - val_loss: 1.5100e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00024 to 0.00015, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 44/100\n",
      "25600/25600 [==============================] - 25s 969us/step - loss: 0.0020 - acc: 0.9996 - val_loss: 6.3691e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00015\n",
      "Epoch 45/100\n",
      "25600/25600 [==============================] - 25s 967us/step - loss: 0.0022 - acc: 0.9997 - val_loss: 1.1106e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00015 to 0.00011, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 46/100\n",
      "25600/25600 [==============================] - 25s 970us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 9.6236e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00011 to 0.00010, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 47/100\n",
      "25600/25600 [==============================] - 25s 970us/step - loss: 0.0017 - acc: 0.9996 - val_loss: 2.1346e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00010\n",
      "Epoch 48/100\n",
      "25600/25600 [==============================] - 25s 975us/step - loss: 0.0014 - acc: 0.9998 - val_loss: 5.4415e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00010 to 0.00005, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 49/100\n",
      "25600/25600 [==============================] - 25s 975us/step - loss: 0.0013 - acc: 0.9998 - val_loss: 8.5885e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00005\n",
      "Epoch 50/100\n",
      "25600/25600 [==============================] - 25s 971us/step - loss: 9.0412e-04 - acc: 0.9999 - val_loss: 3.0549e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00005\n",
      "Epoch 51/100\n",
      "25600/25600 [==============================] - 25s 966us/step - loss: 9.5865e-04 - acc: 0.9999 - val_loss: 3.6815e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00005 to 0.00004, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 52/100\n",
      "25600/25600 [==============================] - 25s 965us/step - loss: 0.0012 - acc: 0.9998 - val_loss: 1.0664e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.00004\n",
      "Epoch 53/100\n",
      "25600/25600 [==============================] - 25s 964us/step - loss: 5.9484e-04 - acc: 1.0000 - val_loss: 1.8584e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00004 to 0.00002, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 54/100\n",
      "25600/25600 [==============================] - 25s 974us/step - loss: 9.0925e-04 - acc: 0.9999 - val_loss: 4.5120e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.00002\n",
      "Epoch 55/100\n",
      "25600/25600 [==============================] - 25s 973us/step - loss: 0.0013 - acc: 0.9998 - val_loss: 1.6969e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00002 to 0.00002, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 56/100\n",
      "25600/25600 [==============================] - 25s 970us/step - loss: 6.3622e-04 - acc: 0.9999 - val_loss: 1.6719e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00002 to 0.00002, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 57/100\n",
      "25600/25600 [==============================] - 25s 970us/step - loss: 0.0016 - acc: 0.9996 - val_loss: 1.8521e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.00002\n",
      "Epoch 58/100\n",
      "25600/25600 [==============================] - 25s 973us/step - loss: 5.5219e-04 - acc: 0.9999 - val_loss: 1.2885e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.00002 to 0.00001, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 59/100\n",
      "25600/25600 [==============================] - 25s 969us/step - loss: 3.2724e-04 - acc: 1.0000 - val_loss: 1.0124e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.00001 to 0.00001, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 60/100\n",
      "25600/25600 [==============================] - 25s 966us/step - loss: 3.3088e-04 - acc: 1.0000 - val_loss: 8.1157e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00001 to 0.00001, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 61/100\n",
      "25600/25600 [==============================] - 25s 969us/step - loss: 3.4986e-04 - acc: 1.0000 - val_loss: 7.2152e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00001 to 0.00001, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 62/100\n",
      "25600/25600 [==============================] - 25s 973us/step - loss: 7.5942e-04 - acc: 0.9998 - val_loss: 1.4296e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.00001\n",
      "Epoch 63/100\n",
      "25600/25600 [==============================] - 25s 980us/step - loss: 4.4843e-04 - acc: 1.0000 - val_loss: 7.8082e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.00001\n",
      "Epoch 64/100\n",
      "25600/25600 [==============================] - 25s 976us/step - loss: 2.2358e-04 - acc: 1.0000 - val_loss: 4.8743e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.00001 to 0.00000, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 65/100\n",
      "25600/25600 [==============================] - 25s 973us/step - loss: 1.9074e-04 - acc: 1.0000 - val_loss: 4.4024e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.00000 to 0.00000, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 66/100\n",
      "25600/25600 [==============================] - 25s 969us/step - loss: 5.5433e-04 - acc: 0.9999 - val_loss: 1.7974e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.00000\n",
      "Epoch 67/100\n",
      "25600/25600 [==============================] - 25s 973us/step - loss: 3.3226e-04 - acc: 0.9999 - val_loss: 3.8083e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.00000 to 0.00000, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 68/100\n",
      "25600/25600 [==============================] - 25s 963us/step - loss: 6.1314e-04 - acc: 0.9998 - val_loss: 6.5413e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.00000\n",
      "Epoch 69/100\n",
      "25600/25600 [==============================] - 25s 967us/step - loss: 1.9123e-04 - acc: 1.0000 - val_loss: 3.8430e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.00000\n",
      "Epoch 70/100\n",
      "25600/25600 [==============================] - 25s 966us/step - loss: 2.0048e-04 - acc: 1.0000 - val_loss: 4.5445e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.00000\n",
      "Epoch 71/100\n",
      "25600/25600 [==============================] - 25s 967us/step - loss: 6.8993e-04 - acc: 0.9997 - val_loss: 4.6304e-06 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00071: val_loss did not improve from 0.00000\n",
      "Epoch 72/100\n",
      "25600/25600 [==============================] - 25s 966us/step - loss: 1.8788e-04 - acc: 1.0000 - val_loss: 4.1386e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.00000\n",
      "Epoch 73/100\n",
      "25600/25600 [==============================] - 25s 970us/step - loss: 1.3520e-04 - acc: 1.0000 - val_loss: 2.8296e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.00000 to 0.00000, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 74/100\n",
      "25600/25600 [==============================] - 25s 967us/step - loss: 2.4659e-04 - acc: 1.0000 - val_loss: 2.3944e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.00000 to 0.00000, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 75/100\n",
      "25600/25600 [==============================] - 25s 969us/step - loss: 2.0695e-04 - acc: 1.0000 - val_loss: 2.4477e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.00000\n",
      "Epoch 76/100\n",
      "25600/25600 [==============================] - 25s 967us/step - loss: 1.0993e-04 - acc: 1.0000 - val_loss: 5.0780e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.00000\n",
      "Epoch 77/100\n",
      "25600/25600 [==============================] - 25s 963us/step - loss: 1.2446e-04 - acc: 1.0000 - val_loss: 1.4781e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.00000 to 0.00000, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 78/100\n",
      "25600/25600 [==============================] - 25s 963us/step - loss: 4.9381e-04 - acc: 0.9999 - val_loss: 1.1633e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.00000\n",
      "Epoch 79/100\n",
      "25600/25600 [==============================] - 25s 971us/step - loss: 1.6755e-04 - acc: 1.0000 - val_loss: 1.5362e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.00000\n",
      "Epoch 80/100\n",
      "25600/25600 [==============================] - 25s 971us/step - loss: 8.1986e-05 - acc: 1.0000 - val_loss: 1.4226e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.00000 to 0.00000, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 81/100\n",
      "25600/25600 [==============================] - 25s 966us/step - loss: 5.0834e-05 - acc: 1.0000 - val_loss: 9.9846e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.00000 to 0.00000, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 82/100\n",
      "25600/25600 [==============================] - 25s 971us/step - loss: 0.0010 - acc: 0.9996 - val_loss: 1.1205e-05 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.00000\n",
      "Epoch 83/100\n",
      "25600/25600 [==============================] - 25s 967us/step - loss: 1.3948e-04 - acc: 1.0000 - val_loss: 2.0226e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.00000\n",
      "Epoch 84/100\n",
      "25600/25600 [==============================] - 25s 972us/step - loss: 1.5393e-04 - acc: 1.0000 - val_loss: 1.2832e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.00000\n",
      "Epoch 85/100\n",
      "25600/25600 [==============================] - 25s 967us/step - loss: 9.8935e-05 - acc: 1.0000 - val_loss: 9.3491e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.00000 to 0.00000, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 86/100\n",
      "25600/25600 [==============================] - 25s 972us/step - loss: 1.1640e-04 - acc: 1.0000 - val_loss: 1.0280e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.00000\n",
      "Epoch 87/100\n",
      "25600/25600 [==============================] - 25s 972us/step - loss: 1.1985e-04 - acc: 1.0000 - val_loss: 1.0009e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.00000\n",
      "Epoch 88/100\n",
      "25600/25600 [==============================] - 25s 971us/step - loss: 4.8162e-05 - acc: 1.0000 - val_loss: 1.0242e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.00000\n",
      "Epoch 89/100\n",
      "25600/25600 [==============================] - 25s 967us/step - loss: 4.6479e-05 - acc: 1.0000 - val_loss: 5.3138e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.00000 to 0.00000, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 90/100\n",
      "25600/25600 [==============================] - 25s 967us/step - loss: 9.5733e-05 - acc: 1.0000 - val_loss: 7.4795e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.00000\n",
      "Epoch 91/100\n",
      "25600/25600 [==============================] - 25s 970us/step - loss: 4.3045e-04 - acc: 0.9999 - val_loss: 1.1917e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.00000\n",
      "Epoch 92/100\n",
      "25600/25600 [==============================] - 25s 969us/step - loss: 4.7334e-05 - acc: 1.0000 - val_loss: 1.0949e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.00000\n",
      "Epoch 93/100\n",
      "25600/25600 [==============================] - 25s 970us/step - loss: 5.1508e-05 - acc: 1.0000 - val_loss: 6.4414e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.00000\n",
      "Epoch 94/100\n",
      "25600/25600 [==============================] - 25s 970us/step - loss: 3.7211e-04 - acc: 0.9999 - val_loss: 2.6067e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.00000\n",
      "Epoch 95/100\n",
      "25600/25600 [==============================] - 25s 971us/step - loss: 3.0217e-04 - acc: 0.9998 - val_loss: 2.6455e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.00000\n",
      "Epoch 96/100\n",
      "25600/25600 [==============================] - 25s 966us/step - loss: 7.0324e-05 - acc: 1.0000 - val_loss: 1.2483e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.00000\n",
      "Epoch 97/100\n",
      "25600/25600 [==============================] - 25s 975us/step - loss: 3.3072e-05 - acc: 1.0000 - val_loss: 5.4834e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.00000\n",
      "Epoch 98/100\n",
      "25600/25600 [==============================] - 25s 969us/step - loss: 3.4367e-05 - acc: 1.0000 - val_loss: 4.2190e-07 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.00000 to 0.00000, saving model to ./checkpoints/best.hdf5\n",
      "Epoch 99/100\n",
      "25600/25600 [==============================] - 25s 967us/step - loss: 9.5241e-04 - acc: 0.9998 - val_loss: 6.1706e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.00000\n",
      "Epoch 100/100\n",
      "25600/25600 [==============================] - 25s 969us/step - loss: 9.9991e-05 - acc: 1.0000 - val_loss: 1.1031e-06 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.00000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8a9a2cc7b8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, \n",
    "          y_train, \n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=(x_val, y_val),\n",
    "          shuffle='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicts = model.predict(x_test)\n",
    "n_samples = x_test.shape[0]\n",
    "pred = np.argmax(predicts, axis=1)\n",
    "print(accuracy_score(pred,y_test))\n",
    "array = confusion_matrix(y_test, pred)\n",
    "cm = pd.DataFrame(array, index = range(n_classes), columns = range(n_classes))\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
